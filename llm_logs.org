Give that the task is:
"""
Compute the pass forward for a single perceptron layer.

"""
Forward pass for a single perceptron layer.
"""
import numpy as np
import test

# Weights and bias are given
W = np.array([
    [1, 0, 1],
    [-1, 0, -1],
    [0.1, 1, 0.1]]) # You will leran more about initialzing the weights later.
b = np.array([-1.0, 0.1, 0.001])
# A sample feature vector
X = np.array([0.9, 0.7, 0.3])

# The sigmoid activation function
def sigmoid(z):
    return 1/(1+np.exp(-z))

# Write your code here
def perceptron_forward(x, W, b, activation=sigmoid):
    """
    Computes the passforward for a feture input X
    using weights W, bias b, and activation function activation.
    """
    # Write your solution here!!!
    a = np.zeros(W.shape[1])
    return a
"""

Ok write a unitest for the perceptron_forward(x, W, b, activation=sigmoid) function.
- include a test for correctness_sample for the case of the sample
- include a test for correctness_3_3 for the case of 3 inputs and three neurons
- include a test for correctness_2_3 for the case of 2 inputs and three neurons
- include a test for zero weights
- include a test for zero inputs
- include a test for different activation
- include a test for bias well managed
- include a test for weights correctly applied

I want to use the test from the notebook as test_task1(feed_forward) from then to print the test results.

To accommodate your requirements and structure the unit tests for the `perceptron_forward` function, here's how you might set it up. Note that I'll use a notebook cell to define the tests as a Python list for easier execution and to mirror your setup requirements:

```python
import numpy as np

def test_task1(perceptron_forward):
    # Test 1: correctness_sample using the provided example
    def correctness_sample():
        X = np.array([0.9, 0.7, 0.3])
        W = np.array([
            [1, 0, 1],
            [-1, 0, -1],
            [0.1, 1, 0.1]])
        b = np.array([-1.0, 0.1, 0.001])
        expected_output = sigmoid(np.dot(W, X) + b)
        output = perceptron_forward(X, W, b)
        assert np.allclose(output, expected_output), "Failed correctness_sample test"
        print("correctness_sample test passed")

    # Test 2: correctness_3_3
    def correctness_3_3():
        X = np.array([1.0, 2.0, 3.0])
        W = np.array([
            [1, 2, 3],
            [4, 5, 6],
            [7, 8, 9]])
        b = np.array([0.1, 0.2, 0.3])
        expected_output = sigmoid(np.dot(W, X) + b)
        output = perceptron_forward(X, W, b)
        assert np.allclose(output, expected_output), "Failed correctness_3_3 test"
        print("correctness_3_3 test passed")

    # Test 3: correctness_2_3
    def correctness_2_3():
        X = np.array([1.0, 2.0])
        W = np.array([
            [1, 2],
            [3, 4],
            [5, 6]])
        b = np.array([0.1, 0.2, 0.3])
        expected_output = sigmoid(np.dot(W, X) + b)
        output = perceptron_forward(X, W, b)
        assert np.allclose(output, expected_output), "Failed correctness_2_3 test"
        print("correctness_2_3 test passed")

    # Test 4: zero weights
    def zero_weights():
        X = np.array([1.0, 2.0, 3.0])
        W = np.zeros((3, 3))
        b = np.array([0, 0, 0])
        expected_output = sigmoid(b)
        output = perceptron_forward(X, W, b)
        assert np.allclose(output, expected_output), "Failed zero_weights test"
        print("zero_weights test passed")

    # Test 5: zero inputs
    def zero_inputs():
        X = np.zeros(3)
        W = np.array([
            [1, 0, 1],
            [0, 1, 0],
            [1, 0, 1]])
        b = np.array([0, 0, 0])
        expected_output = sigmoid(b)
        output = perceptron_forward(X, W, b)
        assert np.allclose(output, expected_output), "Failed zero_inputs test"
        print("zero_inputs test passed")

    # Test 6: different activation
    def different_activation():
        def relu(z):
            return np.maximum(0, z)
          
        X = np.array([1, 2])
        W = np.array([
            [1, -1],
            [-1, 1],
            [1, 1]])
        b = np.array([-1, 1, 0])
        expected_output = relu(np.dot(W, X) + b)
        output = perceptron_forward(X, W, b, activation=relu)
        assert np.allclose(output, expected_output), "Failed different_activation test"
        print("different_activation test passed")

    # Test 7: bias well managed
    def bias_well_managed():
        X = np.array([1.0, 0.0, 0.0])
        W = np.identity(3)
        b = np.array([1.0, 1.0, 1.0])
        expected_output = sigmoid(X + b)
        output = perceptron_forward(X, W, b)
        assert np.allclose(output, expected_output), "Failed bias_well_managed test"
        print("bias_well_managed test passed")

    # Test 8: weights correctly applied
    def weights_correctly_applied():
        X = np.array([0.0, 1.0, 2.0])
        W = np.array([
            [1, 0, 1],
            [0, 1, 0],
            [1, 0, 1]])
        b = np.array([0.0, 0.0, 0.0])
        expected_output = sigmoid(np.dot(W, X) + b)
        output = perceptron_forward(X, W, b)
        assert np.allclose(output, expected_output), "Failed weights_correctly_applied test"
        print("weights_correctly_applied test passed")

    # Run all tests
    correctness_sample()
    correctness_3_3()
    correctness_2_3()
    zero_weights()
    zero_inputs()
    different_activation()
    bias_well_managed()
    weights_correctly_applied()
```

To run the tests, simply call `test_task1(perceptron_forward)` in your notebook after ensuring the function `perceptron_forward` is defined and available. This will execute each test case and print the results directly in the notebook.
